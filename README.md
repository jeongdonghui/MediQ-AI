# MediQ-AI
MediQ medical AI project 개발 일지

## **1. 초기 논문 실험: Qwen2.5-1.5B-Instruct 기반 정규화 테스트**

### ✔ 진행한 내용
- 논문 작성을 위해 가장 처음 수행한 정규화 실험은 **BioBERT가 아닌 Qwen2.5-1.5B-Instruct** 모델로 진행함.
- 사용자 구어체 증상을 **의학 표준 용어 한 단어로 정규화**하도록 제약(prompt) 설계.
- “한 단어만 출력”, “의학 용어 목록 중 하나 선택” 등 LLM 제약 방식 적용.

### ✔ 예시
- 입력: “속이 울렁거리고 토할 것 같아요”
- 출력: “메스꺼움”

### ✔ 느낀 문제점
- LLM의 자유도가 높아 **표준 용어 출력이 일관적이지 않음**
    - “메스꺼움 / 울렁거림 / 구토”처럼 상황별로 다르게 출력
- 정규화 시스템을 구축하기 위해서는 → **“용어 표준화” + “용어 집합 통제”가 필수**라는 결론 도출.
    

## **2. BioBERT 테스트 (HuggingFace)**

### ✔ 진행한 내용
- 정규화 일관성 문제를 해결하고자 **의학 전문 BERT** 탐색 시작.
- HuggingFace에서 BioBERT 모델 로드 및 테스트 환경 구축 (Jupyter Notebook).
- 임베딩 확인, 간단한 문장 실험 진행.

### ✔ 문제점
- **영어 모델이라 한국어 증상 처리 불가.**
- 한국 의료 용어 기반 정규화에는 적합하지 않다는 결론.

## **3. KoBERT / KorBERT 등 한국어 모델 후보 검토**

### ✔ 진행한 내용
- BioBERT가 영어라서 한국어 모델을 검토:
    - KoBERT
    - KorBERT
    - KLUE-BERT
- 구문 이해력은 좋지만 **의학 도메인 전문성이 부족**함을 확인.

### ✔ 결론
- MediQ 정규화 기능에는 → **한국어 + 의료 특화** 조건이 반드시 필요.
    

# **4. KM-BERT 적용 직전 데이터 탐색 단계 (AI Hub 데이터 분석)**

정규화 파이프라인을 KM-BERT로 구성하기 전에, 우리는 “실제 한국 사용자들이 증상을 어떻게 말하는지” 파악하기 위해 AI Hub에서 관련 데이터셋을 탐색했다.
이 과정은 **RULES 설계 방향을 잡는 데 매우 중요한 근거**가 되었음.

## **4-1. 031. 온라인 구어체 말뭉치 데이터**

### ✔ 데이터 개요
- SNS, 커뮤니티, 온라인 대화 등 다양한 환경에서 수집된 **자연스러운 한국어 구어체 문장 데이터**
- 의료 도메인에 제한된 데이터는 아니지만,
-  **사람들이 일상적으로 감정·신체 상태·불편함을 어떻게 표현하는지**를 관찰할 수 있음
    

### ✔ 이 데이터에서 얻은 핵심 인사이트

- 구어체 표현의 다양성이 예상보다 훨씬 넓음
    - “배가 묵직함”
    - “속이 울렁울렁함”
    - “머리가 땡김”
    - “토할 것처럼 메스꺼움”
- 인터넷에서 사용하는 변형 표현, 줄임말, 과장형 표현도 매우 많음
- 이로 인해 RULES(룰 기반 선분류) 방식만으로 정규화를 수행하기 어렵다는 점을 명확히 확인함

➡️ **정규화 시스템은 단순 문자열 매칭이 아니라 의미 기반 접근 필요 → KM-BERT 모델 적용 근거 강화**

## **4-2. 120. 초거대AI 사전학습용 헬스케어 질의 데이터**

### ✔ 데이터 개요
- 실제 사용자가 병원·건강 관련 질문을 자연어로 질의한 데이터를 포함
- “증상 → 원인”, “증상 → 어떤 과?”, “증상 → 병원 가야 하나?” 등
- 일반인이 의료 진단을 어떻게 질문하고 표현하는지 확인 가능

### ✔ 이 데이터가 준 시사점

- 대부분의 질문이 **의학 용어가 아닌 구어체 기반**
    - “콧물 계속 나는데 왜 이래요?”
    - “가슴이 답답하고 숨쉬기 힘듦”
    - “속이 더부룩함 → 병원 가야 하나요?”
- 증상 표현 방식이 우리가 설계하려는 정규화 파이프라인과 일치함
- 사용자의 실제 말투 기반으로 TERMS(표준 용어), RULES(카테고리), PROMPT 구조를 설계해야 한다는 확신을 줌
➡️ 이 데이터는 **MediQ 서비스가 해결하려는 문제(구어체 → 의료용어 정규화)**가 실제 사용자 니즈와 정확히 맞다는 근거가 됨

# **5. KM-BERT 선택 및 테스트 단계**

### ✔ 왜 KM-BERT를 최종 선택했는가?
- 한국어로 학습된 BERT 기반 모델
- 의료 용어/증상/질환 데이터를 포함하여 도메인 이해도가 높음
- 우리가 정한 TERMS(정규화 용어)와 자연스럽게 매칭 가능
- Qwen/BioBERT/KoBERT의 단점을 모두 보완

### ✔ 진행한 테스트
- KM-BERT 모델 로드 및 인퍼런스 실행 확인
- 구어체 입력에 대해 의료 용어로 잘 수렴하는지 실험
- 파이프라인 구조에 통합해도 성능 및 속도 문제 없음

KM-BERT는 “룰 기반 선분류 + 모델 기반 용어 선택 + 강제 매핑” 구조와 가장 잘 맞는 모델로 판단됨.

# **6. MediQ 정규화 파이프라인 구축**

KM-BERT를 정규화 모델로 채택한 뒤, 우리는 실제 운영 가능한 파이프라인을 만들기 위해
데이터 준비 → 용어 정의 → 규칙 구축까지 직접 작업을 진행했다.
이 섹션은 우리가 **직접 만든 파일을 중심으로** 작성한 “실제 개발 내용”이다.

## **6-1. AI Hub JSON → CSV 변환 작업 (데이터 준비 단계)**

우리는 AI Hub 데이터(031, 120)를 분석하기 위해 먼저 JSON 데이터를 CSV로 변환하는 전처리 과정을 직접 진행했다.

### ✔ 실제로 한 작업

- JSON 구조 파악 후 필요한 key만 추출
- Python으로 JSON → CSV 변환 코드 작성
- Pandas로 CSV 형태로 정제하여 불러오기 성공
- CSV에서 “사용자 표현(구어체)”만 따로 필터링해 정규화 설계 자료로 사용

➡️ **이 CSV 파일이 이후 모든 라벨링 및 규칙 설계의 기반이 됨**

## **6-2. 구어체 표현 분석 및 라벨링 초안 구축**

CSV 데이터를 열어 실제 사용자들이 증상을 어떻게 표현하는지 하나씩 확인하며 정규화 용어(라벨)의 필요성을 직접 확인했다.
예시로 발견했던 표현들:
- “머리가 깨질 듯 아파요”
- “토할 것 같음”
- “배가 미식거림”
- “콧물이 줄줄 나옴”

이 분석을 기반으로 **라벨링 기준을 세우기 시작했다.**

## **6-3. 우리가 직접 만든 TERMS 파일: `mediq_labels_final.csv`**

이 파일은 우리가 직접 구축한 **정규화 의학 용어 세트(라벨셋)**이다.
MediQ의 핵심 결과물 중 하나.

### ✔ 실제로 포함된 항목

- 각 증상을 대표하는 표준 의학 용어
- 라벨명(정규화된 명칭)
- 약 1차 의료(상기도·소화기·근골격계 중심) 용어들로 구성
- KM-BERT가 선택하는 기준이 되는 "정답 용어 집합"

예시:
- 두통
- 복통
- 구토/메스꺼움
- 설사
- 기침
- 콧물
- 인후통
- 근육통

➡️ 이 파일은 **정규화 시스템의 핵심 표준 용어집**이며 KM-BERT가 선택하는 모든 최종 결과의 기준이 됨.

## **6-4. 우리가 실제로 만들기 시작한 RULES 파일: `mediq_scope_rules.csv`**

이 파일은 **구어체 표현을 기반으로 카테고리를 분류하는 스코프룰(RULES)**이다.
우리는 이 파일을 직접 만들기 시작했고, 현재 진행 중이다.

### ✔ RULES에서 실제로 기록된 것

- 구어체 트리거 단어
- 해당 단어가 속하는 카테고리(scope)
- 예:
| keyword | scope |
| --- | --- |
| "머리" | upper |
| "토할" | digestive |
| "기침" | respiratory |
| "콧물" | respiratory |
| "근육" | musculoskeletal |

지금은 **초기 버전**으로

우리가 실제로 파일에 작성한 단어들을 기반으로 규칙을 점점 확장하고 있는 단계다.

### ✔ RULES 구축하면서 우리가 실제로 느끼는 문제점

- 단어가 여러 범위에 걸림
- 추상적 표현(묵직함, 답답함 등)은 스코프 분류 어려움
- 표현 다양성 때문에 RULES 수가 폭발적으로 늘어남
- 규칙이 충돌하는 경우가 생김
    
    ➡️ 그래서 “RULES + KM-BERT 결합형 파이프라인”이 필요하다는 판단으로 이어짐
    

## **6-5. KM-BERT 기반 정규화 흐름 테스트 (초기 버전 실행 성공)**

우리는 직접 만든:

- TERMS = `mediq_labels_final.csv`
- RULES = `mediq_scope_rules.csv`

이 두 가지를 조합하여

실제로 KM-BERT가 TERMS 중 하나를 선택하는 초기 파이프라인 테스트를 수행했다.

### ✔ 실제 테스트 예시

입력: “머리가 깨질 듯 아파요”

- RULES: upper 범위로 분류
- KM-BERT: TERMS 중 “두통” 선택
    
    → 출력 성공
    

입력: “토할 것 같고 속이 울렁거림”

- RULES: digestive
- KM-BERT: “메스꺼움/구토” 선택
    
    → 출력 성공
    

➡️ 즉, 파이프라인의 가장 중요한 **A → B → C 흐름이 실제로 작동함을 확인한 단계**임.

---

## **6-6. 지금까지 우리가 실제로 만든 정규화 파이프라인 구성요소 요약**

| 구성 요소 | 실제 구현 여부 | 파일 | 설명 |
| --- | --- | --- | --- |
| TERMS(표준 의학 용어) | ✅ 실제로 완성 | `mediq_labels_final.csv` | 정규화 결과가 되는 의학 용어 리스트 |
| RULES(구어체 → 범위) | ⚙️ 작성 중 | `mediq_scope_rules.csv` | KM-BERT 입력 범위 조정용 규칙 세트 |
| JSON → CSV 변환 | ✅ 완료 | 생성한 CSV 파일 | AI Hub 원본 데이터 전처리 |
| KM-BERT 정규화 테스트 | ✅ 동작 확인 | 노트북 환경 | RULES + TERMS 조합 테스트 성공 |

➡️ **즉, 우리는 이미 정규화 시스템의 핵심 뼈대를 전부 구축했다.**

(TERMS 완성 + RULES 구축 시작 + 파이프라인 작동 성공)

# **7. RULES 설계 단계에서 마주친 주요 문제들**

`mediq_scope_rules.csv` 파일을 작성해 나가면서, 우리는 규칙 기반 선분류(RULES)의 한계들을 직접 경험했다.

이 과정은 결론적으로 **"RULES + KM-BERT 하이브리드 구조"가 필요한 이유**를 명확히 보여준 단계다.

---

## **7-1. 표현 다양성 문제**

CSV 데이터에서 수집한 구어체 표현은 매우 다양했고,

동일 증상이라도 표현 방식이 끝없이 변형되었다.

예:

- “토할 것 같음”
- “미식거림”
- “속이 울렁거림”
- “속이 뒤집히는 것 같음”

➡️ **하나의 RULE에 단순 매핑할 수 없을 정도로 표현이 넓음**

---

## **7-2. 다중 범위(multi-scope) 문제**

특정 표현이 상기도·소화기·근골격계 등

여러 카테고리에 동시에 연결될 수 있었다.

예:

- “답답함” → 흉부 OR 위장 OR 호흡기
- “묵직함” → 두통 OR 복통
- “화끈거림” → 피부 OR 위장 OR 목

➡️ 하나의 keyword가 여러 scope에 걸리면서 RULES 충돌 발생.

---

## **7-3. 비유적·감각적 표현 처리 불가 문제**

RULES는 결국 문자열 기반이기 때문에

비유적 표현을 처리할 수 없었다.

예:

- “심장이 덜컥 내려앉는 느낌”
- “속에서 불이 난다”
- “머리가 띵하다”

➡️ 문자열 키워드로 잡히지 않음 → 규칙 기반만으로는 불가능.

---

## **7-4. RULES가 커질수록 관리 난이도 증가**

RULES를 추가하면 할수록 문제는 더 복잡해짐:

- 비슷한 단어라도 맥락에 따라 다른 과가 될 수 있음
- 우선순위(priority) 체계가 필요함
- 스코프 경계가 모호해서 HUMAN LABELING 자체가 어려움

➡️ 실제 구축한 RULES 파일(`mediq_scope_rules.csv`)에서도

중복/충돌 문제가 계속 발견됨.

---

## ✔ RULES 단계 결론

우리는 이 문제들을 실제로 경험하면서 다음을 명확히 알게 됨:

> RULES만으로는 절대 정규화 불가능하다.
따라서 RULES는 1차 필터링 역할만 하고,
최종 정규화는 반드시 KM-BERT 모델이 담당해야 한다.
> 

이 결론은 MediQ 정규화 구조의 핵심 설계 철학이 되었다.

# **8. KM-BERT 기반 정규화 구조 고도화**

RULES 문제를 경험한 후, 우리는 **KM-BERT를 활용하여 표준 TERMS 중 하나를 선택하도록 하는 구조**를 강화하기 시작했다.

---

## **8-1. TERMS 기반 선택 구조 안정화**

KM-BERT가 선택할 수 있는 후보를

`mediq_labels_final.csv`에 기록된 TERMS로 제한하여

출력 결과의 일관성을 확보했다.

KM-BERT 출력 → TERMS 중 1개

이 구조는 실제 테스트에서도 안정적으로 동작했다.

---

## **8-2. RULES는 범위 축소 역할만 부여**

RULES는 "정답을 찾는 역할"이 아니라,

"KM-BERT가 참고할 범위를 좁혀주는 역할"로 재정의했다.

예:

- 입력 문장: “토할 것 같아요”
    
    → RULES: digestive 범위
    
    → KM-BERT: TERMS 중 ‘메스꺼움/구토’ 선택
    

이 구조로 테스트했을 때 모델의 정확도가 크게 높아짐.

---

## **8-3. 정규화 파이프라인 전체 흐름 안정화**

우리는 테스트를 통해

정규화 시스템이 다음 구조로 돌아가는 것을 확인했다:

1. 사용자가 구어체로 입력
2. RULES로 대략적인 범위(scope) 분리
3. KM-BERT가 그 범위에서 TERMS 중 하나를 선택
4. 그 결과를 표준 의학 용어로 매핑
5. 최종적으로 진료과 추천까지 연결 가능

➡️ MediQ가 가장 중요하게 의도한 **"구어체 → 전문 용어 변환" 기능이 실제 구현됨**

---

# **9. 현재 진행 중이거나 다음 단계에서 해야 할 작업**

지금까지의 작업을 기반으로, 현재 진행 중인 작업과 앞으로 필요한 작업을 정리하면 아래와 같다.

---

## **9-1. RULES 보완 작업 (진행 중)**

- `mediq_scope_rules.csv` 파일을 보완하며 단어 추가
- 다중 스코프 문제 해결을 위한 규칙 재정렬
- 중복 규칙 제거
- 더 많은 구어체 표현(특히 비유형) 수집 예정

---

## **9-2. TERMS 확장 (예정 또는 진행 중)**

`mediq_labels_final.csv`는 1차 의료 중심으로 작성되어 있으므로, 향후 필요한 경우 확장 필요:

- 피부과 관련 증상
- 정신과적 표현(불안, 공황 등)
- 신경계 추가 용어(저림, 마비 등)

---

## **9-3. KM-BERT 파인튜닝(Optional)**

향후 필요시:

- 우리가 구축한 dataset으로 KM-BERT 파인튜닝
- 정규화 정확도 향상 기대 가능

---

## **9-4. FastAPI 기반 inference 서버 구축 (예정)**

정규화 모델을 실제 앱(MediQ)에서 사용하려면:

- 입력을 서버로 보내서
- RULES → KM-BERT → TERMS → 결과
    
    이 흐름을 API 형태로 구현할 계획
    

---

## **9-5. 평가 지표 구축 (예정)**

논문 4장 구조에 맞춘:

- 혼동행렬(confusion matrix)
- 정확도/정밀도/재현율
- 오류 사례 분석 표

등을 향후 구축해야 함.

---

# 전체 요약 (우리의 실제 진행 상황만 기반)

1. AI Hub JSON → CSV 변환 직접 수행
2. 구어체 표현 분석
3. `mediq_labels_final.csv` (TERMS) 직접 제작
4. `mediq_scope_rules.csv` (RULES) 제작 시작
5. RULES 충돌·다중스코프 문제 실제로 경험
6. RULES 단독 구조의 한계 발견
7. KM-BERT로 TERMS 중 1개 선택 구조 테스트 성공
8. 정규화 파이프라인 실제로 작동 확인
9. RULES 보완 및 파이프라인 고도화 진행 중

---

26년 1월11일 진행 일지
### UI 토큰 표준 CSV 생성
위 분류 체계를 기반으로
`MediQ_UI_Tokens_v1.csv` 파일을 생성하였다.
CSV 구성:
- `level`  
    (BODY_PART / REGION / SUB_REGION / MICRO_LOCATION) 
- `code` 
    → 내부에서 사용하는 **고정 토큰**
- `ko_label`
    → UI에 표시되는 한글 라벨
- `parent_code`
    → 상위 토큰 연결 (트리 구조)
- `notes_examples`
    → 설명 및 예시

📌 이 CSV는 **학습 데이터가 아니라 정책/구조 데이터**로 사용됨.

---

### KM-BERT GPU 환경에서 CSV 로딩 및 검증

- `KMBERTGPU3.ipynb` 환경에서 CSV 로딩 시도
- Windows + OneDrive 환경 특성으로 인해:
    - raw string(`r""`) 필요
    - 실제 파일명에 언더스코어(`_`) 중복 이슈 발생
- `os.listdir()`로 **실제 파일명 확인 후 정확히 로딩 성공**

최종 확인:

- `df_tokens.head()` 정상 출력
- BODY_PART 5개 정상 확인

---

### UI 토큰 유틸리티 구성

`df_tokens`를 기반으로 다음 유틸리티를 구성:

- `TOKEN_CODES`
    
    → 유효한 토큰 검증용 set
    
- `CODE2KO`
    
    → code → 한글 라벨 변환
    
- `KO2CODES`
    
    → 한글 라벨 → code 리스트 (중복 대비)
    
- 토큰 무결성 검증 로직
    - code 중복 여부
    - parent_code 누락 여부

이를 통해 **UI에서 잘못된 토큰이 들어오는 경우 즉시 차단 가능**하도록 설계함.

---

### SymptomInput 표준 구조 정의

UI 입력을 AI/룰에서 공통으로 사용하는

**표준 증상 입력 구조(SymptomInput)**를 정의하였다.

```json
{
"body_part":"...",
"region":"...",
"sub_region":"...",
"micro_location":"...",
"feeling":"...",
"intensity":0-10,
"onset":"...",
"associated":[...],
"free_text":"..."
}

```

- 선택형 입력은 **모두 코드값으로 유지**
- 자유 텍스트는 `free_text`에만 포함
- 구조화 입력과 텍스트 입력을 **명확히 분리**

---

### `build_symptom_input()` 함수 구현

- UI 상태(`ui_state`)를 받아
- 유효성 검증을 거친 후
- 표준 `SymptomInput` dict로 변환

주요 특징:

- 토큰 코드 검증
- intensity 타입 정규화
- 선택형/자유 텍스트 혼합 처리

---

### KM-BERT 입력용 텍스트 생성 함수 구현

KM-BERT는 **후보 질환 생성용**으로만 사용하기 때문에,

모델 입력 텍스트는 다음 원칙으로 생성함.

- `free_text`가 있으면 이를 메인으로 사용
- 위치/느낌/강도/시작 시점은 **보조 힌트 형태로만 추가**
- 구조화 입력을 텍스트로 “풀어서” 쓰지 않음

이를 위해 `build_model_text()` 함수 구현.
